{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GL_delineation_geocoded_complex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KNLgtCArppC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCrpI0flVW78",
        "colab_type": "text"
      },
      "source": [
        "# Set up run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-9F0PJRCurK",
        "colab_type": "text"
      },
      "source": [
        "**To do:**\n",
        "\n",
        "\n",
        "*   Change testing cells for compatibility with generator\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78IROuVLJ8g",
        "colab_type": "code",
        "outputId": "db953c22-8e3d-450f-f80a-8cfb2acaa46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#-- Set up configurations / parameters\n",
        "retrain = False # retrain previously existing model\n",
        "ndown = 4 # number of 'down' steps\n",
        "ninit = 32 #number of channels to start with\n",
        "dropout_frac = 0.2 # dropout fraction\n",
        "n_batch = 10\n",
        "n_epochs = 60\n",
        "n_test = 50\n",
        "ratio = 727 # penalization ratio for GL and non-GL points based on smaller dataaset\n",
        "mod_lbl = 'atrous' #'unet'\n",
        "if mod_lbl == 'unet':\n",
        "  mod_str = '{0}_{1}init_{2}down_drop{3:.1f}'.format(mod_lbl,ninit,ndown,\n",
        "                                                        dropout_frac)\n",
        "elif mod_lbl == 'atrous':\n",
        "  mod_str = '{0}_{1}init_drop{2:.1f}'.format(mod_lbl,ninit,dropout_frac)\n",
        "else:\n",
        "  print('model label not matching.')\n",
        "print(mod_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "atrous_32init_drop0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0iqhtdnvws0",
        "colab_type": "code",
        "outputId": "d030fe22-4584-4c7c-c4f4-c18832244e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#-- Import Modules\n",
        "import os\n",
        "import imp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from google.colab import drive\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.python.client import device_lib\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sR2mHxpv5NU",
        "colab_type": "code",
        "outputId": "3d185e92-c474-47c6-efcb-dce8c3431d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#-- Mount Google Drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VEY8FLTI-WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Directory setup\n",
        "colabdir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "output_dir = '/content/gdrive/My Drive/GL_Learning/'\n",
        "ddir = '/content/gdrive/Shared drives/GROUNDING_LINE_TEAM_DRIVE/ML_Yara/geocoded_v1/'\n",
        "train_dir = os.path.join(ddir,'train_n%i.dir'%n_test)\n",
        "test_dir = os.path.join(ddir,'test_n%i.dir'%n_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJkQl4knwzvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Get list of images\n",
        "fileList = os.listdir(train_dir)\n",
        "train_list = [f for f in fileList if (f.endswith('.npy') and f.startswith('coco'))]\n",
        "fileList = os.listdir(test_dir)\n",
        "test_list = [f for f in fileList if (f.endswith('.npy') and f.startswith('coco'))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1SZivgc6o2Q",
        "colab_type": "code",
        "outputId": "0657feff-4c56-4ee6-b08a-ebe33bf48d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#-- set ID_list to be passed onto data generator class\n",
        "ID_list = [os.path.join(train_dir,f) for f in train_list]\n",
        "N = len(ID_list)\n",
        "print(N)\n",
        "\n",
        "#-- read 1 file to get dimensions\n",
        "im = np.load(ID_list[0])\n",
        "h,wi,ch = im.shape\n",
        "print(h,wi,ch)\n",
        "\n",
        "#-- randomly set aside 10% of data for validation\n",
        "valid_ii = random.sample(range(N),int(0.1*N))\n",
        "train_ii = np.setdiff1d(np.arange(N),valid_ii)\n",
        "#-- setup generator\n",
        "data_generation = imp.load_source('data_generation',os.path.join(colabdir,'data_generation.py'))\n",
        "from data_generation import DataGenerator\n",
        "training_generator = DataGenerator(list(np.array(ID_list)[train_ii]),batch_size=n_batch, dim=(h,wi), \n",
        "\tn_channels=ch, shuffle=True, ratio=ratio)\n",
        "validation_generator = DataGenerator(list(np.array(ID_list)[valid_ii]),batch_size=n_batch, dim=(h,wi), \n",
        "\tn_channels=ch, shuffle=True, ratio=ratio)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n train: 4874, n test 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNEsE3m5UD4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jpPSdhI-MPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Upgrade U-Net model from TF1 to TF2\n",
        "!tf_upgrade_v2 \\\n",
        "  --infile /content/gdrive/My\\ Drive/Colab\\ Notebooks/unet_model.py \\\n",
        "  --outfile /content/gdrive/My\\ Drive/Colab\\ Notebooks/unet_model_v2.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL1rcBCZw_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Import model\n",
        "mod_module = imp.load_source('unet_model',os.path.join(colabdir,'unet_model.py'))\n",
        "#-- set up model\n",
        "if mod_lbl == 'unet':\n",
        "  print('loading unet model')\n",
        "  model = mod_module.unet_model_double_dropout(height=h,width=wi,channels=channels, \n",
        "                                        n_init=ninit,n_layers=ndown,\n",
        "                                        drop=dropout_frac)\n",
        "elif mod_lbl == 'atrous':\n",
        "  print(\"loading atrous model\")\n",
        "  model = mod_module.unet_model_atrous_double_dropout(height=h,width=wi,\n",
        "                                                channels=channels,\n",
        "                                                n_filts=ninit,\n",
        "                                                drop=dropout_frac)\n",
        "else:\n",
        "  print('Model label not correct.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmT7qCY39VzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- compile imported model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',\n",
        "              metrics=['accuracy'],sample_weight_mode=\"temporal\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHk2_b1cIbIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- checkpoint file\n",
        "chk_file = os.path.join(output_dir,'{0}_weights.h5'.format(mod_str))\n",
        "\n",
        "#-- if file exists, read model from file\n",
        "if os.path.isfile(chk_file):\n",
        "  print('Check point exists; loading model from file.')\n",
        "  #-- load weights\n",
        "  model.load_weights(chk_file)\n",
        "else:\n",
        "  print('Model does not previously exist.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN7H0GfWKymx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Train the model\n",
        "if (retrain) or (not os.path.isfile(chk_file)):\n",
        "  print('Training model...')\n",
        "  #-- create checkpoint\n",
        "  model_checkpoint = keras.callbacks.ModelCheckpoint(chk_file, monitor='loss',\n",
        "                                                     verbose=1, \n",
        "                                                     save_best_only=True)\n",
        "  lr_callback = ReduceLROnPlateau(monitor='acc', factor=0.5, patience=5,\n",
        "                                  verbose=1, mode='auto', min_delta=0.0001, \n",
        "                                  cooldown=0, min_lr=0)\n",
        "  # es_callback = EarlyStopping(monitor='val_loss',min_delta=0.0001, patience=5,\n",
        "  #    verbose=1, mode='auto')\n",
        "  #-- now fit the model\n",
        "  history = model.fit_generator(generator=training_generator,\n",
        "                                validation_data=validation_generator,\n",
        "                                use_multiprocessing=True,\n",
        "                                workers=4, epochs=n_epochs,\n",
        "                                shuffle=True, verbose=1,\n",
        "                                callbacks=[lr_callback,model_checkpoint])\n",
        "                                #callbacks=[lr_callback,es_callback,model_checkpoint])\n",
        "\n",
        "  #-- save history to file\n",
        "  outfile = open(os.path.join(output_dir,\n",
        "                        '{0}_history.txt'\n",
        "                        .format(mod_str)),'w')\n",
        "  outfile.write('Epoch loss\\tval_loss\\tacc\\tval_acc\\n')\n",
        "  for i in range(len(history.history['loss'])):\n",
        "      outfile.write('%i\\t%f\\t%f\\t%f\\t%f\\n'%(i,history.history['loss'][i],history.history['val_loss'][i],\\\n",
        "          history.history['acc'][i],history.history['val_acc'][i]))\n",
        "  outfile.close()\n",
        "\n",
        "  #-- Make plots for training history\n",
        "  for item,name in zip(['acc','loss'],['Accuracy','Loss']):\n",
        "    fig = plt.figure(1,figsize=(8,6))\n",
        "    plt.plot(history.history[item])\n",
        "    plt.plot(history.history['val_%s'%item])\n",
        "    plt.title('Model %s'%name)\n",
        "    plt.ylabel(name)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "    plt.savefig(os.path.join(output_dir,\n",
        "                        '{0}_history.pdf'\n",
        "                        .format(mod_str)),format='pdf')\n",
        "    plt.close(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsbiHUo2Texy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Model is trained. Running on Train data...')\n",
        "#-------------------------------\n",
        "#-- First run on training data\n",
        "#-------------------------------\n",
        "out_imgs = model.predict(train_imgs, batch_size=1, verbose=1)\n",
        "out_imgs = out_imgs.reshape(out_imgs.shape[0],h,wi,out_imgs.shape[2])\n",
        "print(out_imgs.shape)\n",
        "\n",
        "#-- make output directory\n",
        "out_dir = os.path.join(output_dir,'Train_predictions.dir',\n",
        "                       '{0}.dir'.format(mod_str))\n",
        "if (not os.path.isdir(out_dir)):\n",
        "  os.mkdir(out_dir)\n",
        "\n",
        "#-- save output images (every 4th image. Not interested in augmented cases)\n",
        "for i,f in enumerate(train_list):\n",
        "  im = image.array_to_img(out_imgs[aug_num*i]) \n",
        "  im.save(os.path.join(out_dir,f.replace('coco.tif','pred.png')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTBZrMRlCN-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.max(out_imgs))\n",
        "print(np.min(out_imgs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrLWkMTMAryy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Read test data\n",
        "test_imgs = np.ones((n_test,h,wi,nch))\n",
        "for i,f in enumerate(img_list[n_train:]):\n",
        "    #-- read image\n",
        "    raster = rasterio.open(os.path.join(test_dir,f))\n",
        "    test_imgs[i,:,:,0] = raster.read(1).real\n",
        "    test_imgs[i,:,:,1] = raster.read(1).imag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZciosNGdHKQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------\n",
        "#-- Run on test data\n",
        "#-------------------------------\n",
        "out_imgs = model.predict(test_imgs, batch_size=1, verbose=1)\n",
        "out_imgs = out_imgs.reshape(out_imgs.shape[0],h,wi,out_imgs.shape[2])\n",
        "print(out_imgs.shape)\n",
        "\n",
        "#-- make output directory\n",
        "out_dir = os.path.join(output_dir,'Test_predictions.dir',\n",
        "                       '{0}.dir'.format(mod_str))\n",
        "if (not os.path.isdir(out_dir)):\n",
        "  os.mkdir(out_dir)\n",
        "\n",
        "#-- save output images\n",
        "for i,f in enumerate(test_list):\n",
        "  im = image.array_to_img(out_imgs[i]) \n",
        "  im.save(os.path.join(out_dir,f.replace('coco.tif','pred.png')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u9H27mHWPQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}